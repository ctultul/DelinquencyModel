01/23 - 24

	•	Got Version 1 Dataset
	•	Create github repo
	•	Study data dictionary
	•	Study pickling techniques and performance gain
	•	Basic EDA and variable transformations

01/25-26

	•	Got some more data  
	•	Clarified some questions
	•	Some more EDA
	•	Filter columns with many missing variables
	•	Fill the missing values with 0 / mean 

01/27 - 30

	•	Evaluate the criteria for input variables
	•	Made the Baseline model
	•	Compile the dataset for modeling
	•	Transform variables to engineer features
	•	Run test models (Random Forest and Logistic Regression separately) and based on results:
	◦	Filter Columns that might carry leakage
	◦	Remove features with high correlation
	◦	Determine the most significant variables

01/31 - 2/3

	•	Code added to generate confusion matrices and ROC curves
	•	Grid search process started
	•	FPR and TPR rates have been studied, it comes out that False Negative cases are extremely low, which is good for the business.
	•	Feature Engineered for model score improvement
	•	Leakage has been considered and attempted to be taken out of model
